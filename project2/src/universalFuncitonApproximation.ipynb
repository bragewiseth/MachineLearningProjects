{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d04768f3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "def step(x):\n",
    "    return np.where(x>=0,1,0)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "\n",
    "###### PLOT SIGMOID AND STEP FUNCTION ########\n",
    "x= np.linspace(-10,10,100)\n",
    "plt.plot(x,sigmoid(x))\n",
    "plt.plot(x,step(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97499677",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(100,2)\n",
    "t_xor = (x[:,0] >= 0.5) ^ (x[:,1] > 0.5)\n",
    "######## PLOT XOR #############################\n",
    "plt.scatter(x[:,0],x[:,1],c=t_xor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xor = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "target = np.array([0,1,1,0])\n",
    "\n",
    "# x = np.repeat(xor,100,axis=0)\n",
    "# t_xor = np.repeat(target,100,axis=0).reshape(-1,1)\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "data = poly.fit_transform(x)\n",
    "\n",
    "def fit(x,target):\n",
    "    w = np.ones((x.shape[1],1))\n",
    "    eta = 0.1\n",
    "    for _ in range(1000):\n",
    "        z = np.dot(x,w)\n",
    "        y = sigmoid(z)\n",
    "        e = y - target\n",
    "        w -= eta * np.dot(x.T,e)\n",
    "    return w\n",
    "\n",
    "\n",
    "\n",
    "X = np.linspace(0,1,10)\n",
    "Y = np.linspace(0,1,10)\n",
    "X,Y = np.meshgrid(X,Y)\n",
    "w = fit(data,t_xor.reshape(-1,1))\n",
    "g = np.concatenate((X.ravel().reshape(-1,1),Y.ravel().reshape(-1,1)),axis=1)\n",
    "g = poly.fit_transform(g)\n",
    "Z = np.dot(g,w)\n",
    "Z = Z.reshape(10,10)\n",
    "Z = sigmoid(Z)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X,Y,Z)\n",
    "ax.scatter(xor[:,0],xor[:,1],target, c=target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99d5c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "# regresion one hidden layer\n",
    "# dimension [1,2,1] \n",
    "np.random.seed(0)\n",
    "params = [{'w':np.random.randn(1,4),'b':np.random.randn(1,4)},{'w':np.random.randn(4,1),'b':np.random.randn(1,1)}]\n",
    "\n",
    "def forward(x,params):\n",
    "    z1 = np.dot(x,params[0]['w']) + params[0]['b']\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1,params[1]['w']) + params[1]['b']\n",
    "    a2 = z2\n",
    "    return a2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tune manually\n",
    "# params[0]['w'] = np.array([[-0.5],[1],[1]]).reshape(1,3)\n",
    "# params[0]['b'] = np.array([[-1.0],[0.],[-2.]]).reshape(1,3)\n",
    "# params[1]['w'] = np.array([[-6.],[-2.],[0.5]]).reshape(3,1)\n",
    "# params[1]['b'] = np.array([[1.]]).reshape(1,1)\n",
    "\n",
    "\n",
    "# mean square error\n",
    "def mse(y,t):\n",
    "    return np.mean((y-t)**2)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x>=0,1,0)\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "def fit(x,target,params):\n",
    "    N = x.shape[0]\n",
    "    eta = 0.04\n",
    "    t = target\n",
    "    for _ in range(10000):\n",
    "        W1 = params[0]['w'] \n",
    "        b1 = params[0]['b']\n",
    "        W2 = params[1]['w']\n",
    "        b2 = params[1]['b']\n",
    "\n",
    "        if not np.isfinite(W1).all() or not np.isfinite(W2).all():\n",
    "            # clip weights\n",
    "            W1 = np.clip(W1, -100, 100)\n",
    "            W2 = np.clip(W2, -100, 100)\n",
    "            print('weights clipped')\n",
    "\n",
    "        if not np.isfinite(b1).all() or not np.isfinite(b2).all():\n",
    "            # clip biases\n",
    "            b1 = np.clip(b1, -100, 100)\n",
    "            b2 = np.clip(b2, -100, 100)\n",
    "            print('biases clipped')\n",
    "\n",
    "\n",
    "        Z1 = x.dot(W1) + b1\n",
    "        H = relu(Z1)\n",
    "        # H = sigmoid(Z1)\n",
    "        Y = H.dot(W2) + b2\n",
    "# Compute output error\n",
    "        error = Y - t\n",
    "# Backward pass (compute gradients)\n",
    "        grad_W2 = H.T.dot(error) / N\n",
    "        grad_b2 = np.sum(error, axis=0, keepdims=True) / N\n",
    "        grad_H = error.dot(W2.T)\n",
    "        # grad_Z1 = grad_H * sigmoid_derivative(Z1)\n",
    "        grad_Z1 = grad_H * relu_derivative(Z1)\n",
    "        grad_W1 = x.T.dot(grad_Z1) / N\n",
    "        grad_b1 = np.sum(grad_Z1, axis=0, keepdims=True) / N\n",
    "\n",
    "        params[0]['w'] -= eta * grad_W1\n",
    "        params[0]['b'] -= eta * grad_b1\n",
    "        params[1]['w'] -= eta * grad_W2\n",
    "        params[1]['b'] -= eta * grad_b2\n",
    "    return params\n",
    "\n",
    "\n",
    "x = np.linspace(-4,4,100)\n",
    "t = -0.1*x**2\n",
    "t = t - np.mean(t)\n",
    "plt.plot(x,t)\n",
    "\n",
    "\n",
    "\n",
    "params = fit(x.reshape(-1,1),t.reshape(-1,1),params)\n",
    "\n",
    "\n",
    "\n",
    "# plot first layer activation\n",
    "z1 = np.dot(x.reshape(-1,1),params[0]['w']) + params[0]['b']\n",
    "a1 = relu(z1)\n",
    "plt.plot(x,a1)\n",
    "\n",
    "\n",
    "y = forward(x.reshape(-1,1),params)\n",
    "plt.plot(x,y)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
